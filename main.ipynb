{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":73231,"databundleVersionId":8365361,"sourceType":"competition"},{"sourceId":4053053,"sourceType":"datasetVersion","datasetId":2398033},{"sourceId":4086339,"sourceType":"datasetVersion","datasetId":2418291},{"sourceId":7369493,"sourceType":"datasetVersion","datasetId":4281572},{"sourceId":7867367,"sourceType":"datasetVersion","datasetId":4615754},{"sourceId":8023365,"sourceType":"datasetVersion","datasetId":4728129},{"sourceId":8052555,"sourceType":"datasetVersion","datasetId":4748944},{"sourceId":8149693,"sourceType":"datasetVersion","datasetId":4819800},{"sourceId":8706919,"sourceType":"datasetVersion","datasetId":5222750},{"sourceId":8707395,"sourceType":"datasetVersion","datasetId":5223082},{"sourceId":8707489,"sourceType":"datasetVersion","datasetId":5223138},{"sourceId":8708282,"sourceType":"datasetVersion","datasetId":5223654},{"sourceId":8708340,"sourceType":"datasetVersion","datasetId":5223698},{"sourceId":8771554,"sourceType":"datasetVersion","datasetId":5263819},{"sourceId":8799694,"sourceType":"datasetVersion","datasetId":5223302}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":272.023448,"end_time":"2024-06-22T22:29:29.890355","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-22T22:24:57.866907","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0da7620dc2854885a88d3c5aca1f8de1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e51797acbeda47ee9f0984077c43c9ad","placeholder":"​","style":"IPY_MODEL_58f367d350be45128556252946c4d090","value":" 3/3 [01:39&lt;00:00, 32.21s/it]"}},"114dc8b22e544c84b2547b8a1a076512":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f97b0ce8b2e416ebc8e58fa6eccafac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_504d7e78f31b426ab38ce7a58b74ac0d","placeholder":"​","style":"IPY_MODEL_114dc8b22e544c84b2547b8a1a076512","value":"Loading checkpoint shards: 100%"}},"281867fd08c44bb6b7bf8ecc5b8b389b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f97b0ce8b2e416ebc8e58fa6eccafac","IPY_MODEL_f90075bba4b84f49ba6cb53a64750fed","IPY_MODEL_0da7620dc2854885a88d3c5aca1f8de1"],"layout":"IPY_MODEL_a207bc4c0e2b48e0ab0eefd5d80215bd"}},"504d7e78f31b426ab38ce7a58b74ac0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58f367d350be45128556252946c4d090":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93b3fad2238a4708b56b9c20b2a8e05f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a207bc4c0e2b48e0ab0eefd5d80215bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdb47d6fd1fa4177a7e453afde09c770":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e51797acbeda47ee9f0984077c43c9ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f90075bba4b84f49ba6cb53a64750fed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93b3fad2238a4708b56b9c20b2a8e05f","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cdb47d6fd1fa4177a7e453afde09c770","value":3}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\ntime_start = time.time()\nimport os\nimport torch\nimport gc\nimport math\nON_KAGGLE = os.path.exists('/kaggle/input')\nENABLE_SUBMISSION = True\nGENERATE_WHL = False\nos.environ[\"ON_KAGGLE\"] = str(ON_KAGGLE)\nenv = None\nos.environ[\"USE_VLLM\"] = \"False\"\n# Clear cache, helps in re-running the notebook\ngc.collect()\ntorch.cuda.empty_cache()\n# This is related to T4 GPU on collab\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)","metadata":{"papermill":{"duration":0.01842,"end_time":"2024-06-22T22:25:01.790016","exception":false,"start_time":"2024-06-22T22:25:01.771596","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-27T07:51:52.318960Z","iopub.execute_input":"2024-06-27T07:51:52.319493Z","iopub.status.idle":"2024-06-27T07:51:59.094378Z","shell.execute_reply.started":"2024-06-27T07:51:52.319466Z","shell.execute_reply":"2024-06-27T07:51:59.093322Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Install required packages if on Kaggle\nif ON_KAGGLE:\n    !pip install -U /kaggle/input/accelerate-wheelwhl/accelerate-0.29.1-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/omegaconf222py3/antlr4_python3_runtime-4.9.3-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/omegaconf222py3/omegaconf-2.2.2-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/hydracore120py3/hydra_core-1.2.0-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/parglare-0-18-0/parglare-0.18.0-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/rank-bm25-whl/rank_bm25-0.2.2-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/huggingface-trl-package/shtab-1.7.1-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/huggingface-trl-package/tyro-0.7.3-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/peft-0-11-1/peft-0.11.1-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/huggingface-trl-package/trl-0.7.11-py3-none-any.whl -qq\n    !pip install -U /kaggle/input/amino-gaz-whl/aimo_gaz-0.0.1-py3-none-any.whl -qq --no-deps --force-reinstall\nelse:\n    !pip install -r requirements.txt\n    !pip install -e . --force-reinstall\nif GENERATE_WHL:\n    !pip install --upgrade build\n    !python -m build","metadata":{"papermill":{"duration":112.26536,"end_time":"2024-06-22T22:26:54.058526","exception":false,"start_time":"2024-06-22T22:25:01.793166","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-27T07:51:59.096555Z","iopub.execute_input":"2024-06-27T07:51:59.097068Z","iopub.status.idle":"2024-06-27T07:58:34.385595Z","shell.execute_reply.started":"2024-06-27T07:51:59.097030Z","shell.execute_reply":"2024-06-27T07:58:34.384222Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import time\nfrom aimo_gaz.solver.solver_config import parse_solver_config\nfrom aimo_gaz.tools.log_utils import setup_logger\nfrom hydra import compose, initialize\n\nconfig_path = '/kaggle/input/aimo-gaz-configs/configs' if ON_KAGGLE else 'src/aimo_gaz/configs'\nconfig_name = 'coordination_solver_config.yaml'\n\n# Setup the logger\nif \"AIMO_GAZ_ROOT\" not in os.environ:\n    os.environ[\"AIMO_GAZ_ROOT\"] = '/kaggle/working' if ON_KAGGLE else 'src/aimo_gaz'\nlog_dir_name = \"logs\" if ON_KAGGLE else '.logs'\nroot_dir = os.environ[\"AIMO_GAZ_ROOT\"]\n# Check if the configs exists in the root directory\nif not os.path.exists(os.path.join(root_dir, 'configs')):\n    os.makedirs(os.path.join(root_dir, 'configs'))\n# Copy the configs to the root directory\nos.system(f'cp -r {config_path}/* {os.path.join(root_dir, \"configs\")}')\n# Create the logs directory\nif not os.path.exists(os.path.join(root_dir, log_dir_name)):\n    os.makedirs(os.path.join(root_dir, log_dir_name), exist_ok=True)\ntime_str = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\nos.makedirs(os.path.join(root_dir, log_dir_name, time_str), exist_ok=True)\nlogger = setup_logger(\"aimo_gaz\", os.path.join(root_dir, log_dir_name, time_str, 'aimo_gaz.log'))\nlogger.info(f\"Using config file: {config_name}\")\nwith initialize(version_base=\"1.2\", config_path=\"configs\", job_name=\"aimo_gaz\"):\n    cfg = compose(config_name=config_name) # Load the config file\n    solver_config = parse_solver_config(cfg)\nsolver = solver_config.get_solver(logger=logger)\nassert solver is not None, \"Solver not initialized\"\n    ","metadata":{"papermill":{"duration":33.955339,"end_time":"2024-06-22T22:27:28.017009","exception":false,"start_time":"2024-06-22T22:26:54.061670","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-27T07:58:34.387203Z","iopub.execute_input":"2024-06-27T07:58:34.387545Z","iopub.status.idle":"2024-06-27T07:58:59.538709Z","shell.execute_reply.started":"2024-06-27T07:58:34.387515Z","shell.execute_reply":"2024-06-27T07:58:59.537749Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-27 07:58:40.462819: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-27 07:58:40.462997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-27 07:58:40.721533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'planner_solver_config.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n  warnings.warn(msg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'execution_solver_config.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n  warnings.warn(msg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'code_solver_config.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n  warnings.warn(msg, UserWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set up the evaluation API\nif ENABLE_SUBMISSION and ON_KAGGLE:\n    import aimo\n    if env is None:\n        env = aimo.make_env()\n    iter_test = env.iter_test()","metadata":{"papermill":{"duration":0.036219,"end_time":"2024-06-22T22:27:28.056329","exception":false,"start_time":"2024-06-22T22:27:28.020110","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-27T08:17:40.195973Z","iopub.execute_input":"2024-06-27T08:17:40.196314Z","iopub.status.idle":"2024-06-27T08:17:40.201850Z","shell.execute_reply.started":"2024-06-27T08:17:40.196290Z","shell.execute_reply":"2024-06-27T08:17:40.200723Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"if ENABLE_SUBMISSION and ON_KAGGLE:\n    prep_time = math.ceil(time.time() - time_start)\n    total_time_left = 9 * 60 * 60 - prep_time - 700 # 9 hours in seconds - time taken for preparation and grace time of 100s\n    test_problems = set([\"What is $1-1$?\", \"What is $0\\times10$?\", \"Solve $4+x=4$ for $x$.\"])\n    reduced_time_for_test_problems = 50\n    with solver:\n        problems_attempted = 0\n        total_problems = 50\n        # Iterate through the test set and use the model make predictions\n        for test, sample_submission in iter_test:\n            start_timer = time.time()\n            print(\"Problem statement:\\n\")\n            problem_statement = str(test['problem'][0])\n            print(problem_statement)\n            if problem_statement in test_problems:\n                time_allowed_to_solve = reduced_time_for_test_problems\n            else:\n                time_allowed_to_solve = total_time_left//(total_problems - problems_attempted)\n            print(f\"Time allowed to solve {time_allowed_to_solve}\")\n            sample_submission['answer'] = solver.solve(problem_statement, time_allowed = time_allowed_to_solve)\n            env.predict(sample_submission)\n            print(\"Submission:\\n\")\n            print(sample_submission, '\\n')\n            print(\"=\"*50)\n            time_to_attempt = math.ceil(time.time() - start_timer)\n            total_time_left -= time_to_attempt\n            problems_attempted += 1\n            if total_time_left <= 0:\n                break","metadata":{"papermill":{"duration":118.880015,"end_time":"2024-06-22T22:29:26.939316","exception":false,"start_time":"2024-06-22T22:27:28.059301","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-27T08:17:44.569778Z","iopub.execute_input":"2024-06-27T08:17:44.570417Z","iopub.status.idle":"2024-06-27T08:17:44.644036Z","shell.execute_reply.started":"2024-06-27T08:17:44.570383Z","shell.execute_reply":"2024-06-27T08:17:44.642858Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m total_problems \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Iterate through the test set and use the model make predictions\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test, sample_submission \u001b[38;5;129;01min\u001b[39;00m iter_test:\n\u001b[1;32m     11\u001b[0m     start_timer \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem statement:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32mcompetition.py:30\u001b[0m, in \u001b[0;36miter_test\u001b[0;34m()\u001b[0m\n","\u001b[0;31mException\u001b[0m: You can only iterate over `iter_test()` once."],"ename":"Exception","evalue":"You can only iterate over `iter_test()` once.","output_type":"error"}]}]}